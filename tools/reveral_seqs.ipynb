{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence generation for the pseudoRWM set of experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import statements and utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_along_axis(arr, axis):\n",
    "    idx = np.random.rand(*arr.shape).argsort(axis=axis)\n",
    "    return np.take_along_axis(arr, idx, axis=axis)\n",
    "\n",
    "\n",
    "def shuffled(arr):\n",
    "    arr_shuffled = arr.copy()\n",
    "    np.random.shuffle(arr_shuffled)\n",
    "    return arr_shuffled\n",
    "\n",
    "\n",
    "def choose_n_and_delete(arr, N):\n",
    "    chosen = np.random.choice(arr, size=N, replace=False)\n",
    "    arr = np.delete(arr, np.where(np.isin(arr, chosen)))\n",
    "    return chosen, arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_type = \"reverse_points\"\n",
    "num_conditions = 10  # number of different file sequences to generate (change if needed)\n",
    "reps_dict = {\n",
    "    \"reverse_points\": 12,\n",
    "}  # number of repetitions after the first presentation\n",
    "num_reps = reps_dict[\n",
    "    exp_type\n",
    "]  # number of stimulus repetitions (after first presentation; change if needed)\n",
    "exact_reps = True  # should the number of repetitions be exact or ok to exceed by 1?\n",
    "\n",
    "\n",
    "# set_size_to_key_list: columns represent keyboard keys\n",
    "# each column says how many stimuli will be associated with that key\n",
    "# e.g., 1, 2, 3 means 1 stimulus will be associated with key 0, 2, with key 1, 3 with key 2,\n",
    "# for a total of 6 items\n",
    "\n",
    "block_structures = (\n",
    "    np.array([1, 2, 3]),\n",
    "    np.array([1, 3, 2]),\n",
    "    np.array([2, 2, 2]),\n",
    "    np.array([3, 2, 1]),            \n",
    ")\n",
    "\n",
    "# Repeat 4 times (by stacking), then shuffle rows\n",
    "repeated_blocks = np.vstack([block_structures for _ in range(4)])\n",
    "np.random.shuffle(repeated_blocks)\n",
    "SET_SIZE_TO_KEY_LIST = {\n",
    "    2: np.vstack(\n",
    "        (\n",
    "            np.array([1, 0, 1]),\n",
    "            np.array([1, 1, 0]),\n",
    "            np.array([0, 1, 1]),\n",
    "            np.array([1, 0, 1]),\n",
    "        )\n",
    "    ),\n",
    "    6: repeated_blocks,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V2 sequence generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_NAME = \"reverse-points/seqv2\"\n",
    "\n",
    "\n",
    "class V2RWMSequenceMaker:\n",
    "    def __init__(\n",
    "        self,\n",
    "        exp_type,\n",
    "        num_reps,\n",
    "        block_structure,\n",
    "        num_conditions=10,\n",
    "        exact_reps=False,\n",
    "    ):\n",
    "\n",
    "        # ================ SETTINGS ==========================================================================\n",
    "        assert exp_type in [\n",
    "            \"reverse_points\",\n",
    "        ], f\"{exp_type} is not a valid exp_type\"\n",
    "        self.exp_type = exp_type\n",
    "        self.num_reps = num_reps\n",
    "        self.num_conditions = num_conditions\n",
    "        self.exact_reps = exact_reps\n",
    "        self.to_dir = f\"/Users/ccnlab/Development/sequences/{DIR_NAME}/\"\n",
    "        self.num_keys = 3\n",
    "        self.max_stims = 6\n",
    "        # list of (set_size, TRIAL TYPES)\n",
    "        self.block_structure = block_structure\n",
    "        self.num_blocks = len(self.block_structure)\n",
    "\n",
    "        self.set_size_to_key_list = SET_SIZE_TO_KEY_LIST\n",
    "    \n",
    "    def make_sequences(self, start_idx=0):\n",
    "        from tqdm import trange\n",
    "\n",
    "        for s_i in trange(self.num_conditions):\n",
    "            # blocks: array of length n with each element representing the block's set size and trial type\n",
    "            blocks = self.block_structure.copy()\n",
    "            # Randomize the first half of the blocks\n",
    "            # for i in range(0, self.num_blocks // 2, 4):\n",
    "            #     # has to do a array copy because of the pointer to set object\n",
    "            #     arr = blocks[i : i + 4]\n",
    "            #     np.random.shuffle(arr)\n",
    "            #     blocks[i : i + 4] = arr\n",
    "\n",
    "            # ================ RULES =============================================================================\n",
    "            # block_rules: a list where each element is a dictionary, with keys representing a stimulus image and\n",
    "            # values representing the solution for each stimulus\n",
    "            # here we shuffle within rows (only the first three columns), so that it's not always the same keys\n",
    "            # that have 1, 2, or 3 stimuli associated with them (no difference for rows with 2, 2, 2)\n",
    "            # mix up stim/action within the rule\n",
    "            R_i = {\n",
    "                ns: shuffle_along_axis(keys, axis=1).tolist()\n",
    "                for ns, keys in self.set_size_to_key_list.items()\n",
    "            }\n",
    "            block_rules = []\n",
    "            for block_i, (ns, _) in enumerate(blocks):\n",
    "                key_mapping = R_i[ns].pop()\n",
    "                block_rules.append(\n",
    "                    {\n",
    "                        i: k\n",
    "                        for i, k in enumerate(\n",
    "                            [\n",
    "                                key_i\n",
    "                                for key_i in range(self.num_keys)\n",
    "                                for _ in range(key_mapping[key_i])\n",
    "                            ]\n",
    "                        )\n",
    "                    }\n",
    "                )\n",
    "            print(block_rules)\n",
    "            # ================ STIMULI ===========================================================================\n",
    "            # stim_sets: stimulus sets (folders from where images will be taken for each block)\n",
    "            stim_sets = np.random.permutation(self.num_blocks) + 1\n",
    "\n",
    "            # block_stimuli: will contain dictionaries with an image number for each stimulus\n",
    "            block_stimuli = []\n",
    "            for block_i, (ns, _) in enumerate(blocks):\n",
    "                block_stimuli.append(\n",
    "                    {\n",
    "                        i: s\n",
    "                        for i, s in enumerate(\n",
    "                            (np.random.permutation(self.max_stims) + 1)[0:ns]\n",
    "                        )\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            # block_seqprototypes: will contain dictionaries for each participant, with keys representing a set size and\n",
    "            # values as lists with a sequence of stimuli to be presented\n",
    "            # create a prototype (corresponding to stimuli rather than stimulus images) for each set size\n",
    "            block_seqprototypes = []\n",
    "\n",
    "            # block_sequences: maps block_seqprototypes to corresponding stimulus sequences based on block_stimuli\n",
    "            block_sequences = []\n",
    "            for block_i, (ns, _) in enumerate(blocks):\n",
    "                # worse (but faster) alternative if createstimsequence doesn't work\n",
    "                temp_seqprototype = []\n",
    "                for _ in range(self.num_reps + 1):\n",
    "                    temp_seqprototype = np.hstack(\n",
    "                        (\n",
    "                            temp_seqprototype,\n",
    "                            (shuffled(np.arange(1, ns + 1))),\n",
    "                        )\n",
    "                    )\n",
    "                block_seqprototypes.append(temp_seqprototype)\n",
    "                # turn into stimuli (stimulus image number)\n",
    "                block_sequences.append(\n",
    "                    np.vectorize((block_stimuli[block_i]).get)(\n",
    "                        block_seqprototypes[block_i] - 1\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            # ================ CSV FILE ==========================================================================\n",
    "            # create csv\n",
    "            # rows: stim, correct key, set size, blocks, img_folders, img_nums, trial_type, is_oneshot\n",
    "            colnames = [\n",
    "                \"stim\",\n",
    "                \"correct_key\",\n",
    "                \"set_size\",\n",
    "                \"block\",\n",
    "                \"img_folder\",\n",
    "                \"stim_img\",\n",
    "                \"trial_type\",\n",
    "                \"is_oneshot\",\n",
    "            ]\n",
    "            is_oneshot_blocks = [7, 14]\n",
    "            for block_i, (ns, block_cond) in enumerate(blocks):\n",
    "                block_length = (self.num_reps + 1) * ns  # number of trials in a block\n",
    "\n",
    "                this_block = np.full((len(colnames), block_length), np.nan)\n",
    "\n",
    "                _, unique_idx = np.unique(block_sequences[block_i], return_index=True)\n",
    "                # block_cond = trial_types[block_i]\n",
    "\n",
    "                this_block[0] = block_seqprototypes[block_i]  # stimulus number\n",
    "                this_block[1] = np.vectorize((block_rules[block_i]).get)(\n",
    "                    block_seqprototypes[block_i] - 1\n",
    "                )  # correct key for the stimulus number\n",
    "                this_block[2] = np.repeat(ns, block_length)  # set size\n",
    "                this_block[3] = np.repeat(block_i + 1, block_length)  # block number\n",
    "                this_block[4] = np.repeat(\n",
    "                    stim_sets[block_i], block_length\n",
    "                )  # image folder\n",
    "                this_block[5] = block_sequences[block_i]  # stimulus number\n",
    "                this_block[6] = np.repeat(block_cond, block_length)  # trial type\n",
    "                this_block[7] = np.repeat(\n",
    "                    block_i + 1 in is_oneshot_blocks, block_length\n",
    "                )  # phase name\n",
    "\n",
    "                if block_i == 0:\n",
    "                    train_seq = this_block\n",
    "                    unique_stims = this_block[:, unique_idx]\n",
    "                else:\n",
    "                    train_seq = np.column_stack((train_seq, this_block))\n",
    "                    unique_stims = np.column_stack(\n",
    "                        (unique_stims, this_block[:, unique_idx])\n",
    "                    )\n",
    "\n",
    "            # save output\n",
    "            np.savetxt(\n",
    "                f\"{self.to_dir}seq{start_idx+s_i+1}_learning.csv\", train_seq, delimiter=\",\"\n",
    "            )\n",
    "\n",
    "        return train_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 242.40it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 343.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{0: 0, 1: 0, 2: 0, 3: 1, 4: 2, 5: 2}, {0: 0, 1: 0, 2: 1, 3: 1, 4: 1, 5: 2}, {0: 0, 1: 0, 2: 1, 3: 1, 4: 1, 5: 2}, {0: 0, 1: 0, 2: 1, 3: 1, 4: 2, 5: 2}, {0: 0, 1: 0, 2: 0, 3: 1, 4: 2, 5: 2}, {0: 0, 1: 1, 2: 1, 3: 1, 4: 2, 5: 2}, {0: 0, 1: 0, 2: 1, 3: 2, 4: 2, 5: 2}, {0: 0, 1: 0, 2: 1, 3: 1, 4: 2, 5: 2}, {0: 0, 1: 0, 2: 1, 3: 1, 4: 2, 5: 2}, {0: 0, 1: 0, 2: 0, 3: 1, 4: 1, 5: 2}, {0: 0, 1: 0, 2: 1, 3: 1, 4: 1, 5: 2}, {0: 0, 1: 0, 2: 1, 3: 1, 4: 2, 5: 2}, {0: 0, 1: 0, 2: 0, 3: 1, 4: 2, 5: 2}, {0: 0, 1: 0, 2: 1, 3: 1, 4: 1, 5: 2}]\n",
      "[{0: 0, 1: 0, 2: 0, 3: 1, 4: 1, 5: 2}, {0: 0, 1: 0, 2: 0, 3: 1, 4: 1, 5: 2}, {0: 0, 1: 0, 2: 1, 3: 1, 4: 1, 5: 2}, {0: 0, 1: 0, 2: 1, 3: 1, 4: 2, 5: 2}, {0: 0, 1: 1, 2: 1, 3: 2, 4: 2, 5: 2}, {0: 0, 1: 0, 2: 1, 3: 1, 4: 1, 5: 2}, {0: 0, 1: 0, 2: 0, 3: 1, 4: 2, 5: 2}, {0: 0, 1: 0, 2: 1, 3: 1, 4: 2, 5: 2}, {0: 0, 1: 0, 2: 1, 3: 1, 4: 2, 5: 2}, {0: 0, 1: 0, 2: 1, 3: 2, 4: 2, 5: 2}, {0: 0, 1: 1, 2: 1, 3: 1, 4: 2, 5: 2}, {0: 0, 1: 0, 2: 1, 3: 1, 4: 2, 5: 2}, {0: 0, 1: 0, 2: 1, 3: 2, 4: 2, 5: 2}, {0: 0, 1: 0, 2: 1, 3: 2, 4: 2, 5: 2}]\n",
      "[{0: 0, 1: 0, 2: 1, 3: 1, 4: 1, 5: 2}, {0: 0, 1: 0, 2: 0, 3: 1, 4: 1, 5: 2}, {0: 0, 1: 0, 2: 0, 3: 1, 4: 2, 5: 2}, {0: 0, 1: 0, 2: 1, 3: 1, 4: 2, 5: 2}, {0: 0, 1: 1, 2: 1, 3: 2, 4: 2, 5: 2}, {0: 0, 1: 0, 2: 0, 3: 1, 4: 1, 5: 2}, {0: 0, 1: 0, 2: 1, 3: 2, 4: 2, 5: 2}, {0: 0, 1: 0, 2: 1, 3: 1, 4: 2, 5: 2}, {0: 0, 1: 0, 2: 1, 3: 1, 4: 2, 5: 2}, {0: 0, 1: 0, 2: 1, 3: 2, 4: 2, 5: 2}, {0: 0, 1: 0, 2: 1, 3: 1, 4: 1, 5: 2}, {0: 0, 1: 0, 2: 1, 3: 1, 4: 2, 5: 2}, {0: 0, 1: 0, 2: 1, 3: 2, 4: 2, 5: 2}, {0: 0, 1: 1, 2: 1, 3: 1, 4: 2, 5: 2}]\n",
      "[{0: 0, 1: 1, 2: 1, 3: 2, 4: 2, 5: 2}, {0: 0, 1: 0, 2: 1, 3: 1, 4: 1, 5: 2}, {0: 0, 1: 1, 2: 1, 3: 1, 4: 2, 5: 2}, {0: 0, 1: 0, 2: 1, 3: 1, 4: 2, 5: 2}, {0: 0, 1: 1, 2: 1, 3: 1, 4: 2, 5: 2}, {0: 0, 1: 0, 2: 1, 3: 1, 4: 1, 5: 2}, {0: 0, 1: 1, 2: 1, 3: 2, 4: 2, 5: 2}, {0: 0, 1: 0, 2: 1, 3: 1, 4: 2, 5: 2}, {0: 0, 1: 0, 2: 1, 3: 1, 4: 2, 5: 2}, {0: 0, 1: 1, 2: 1, 3: 2, 4: 2, 5: 2}, {0: 0, 1: 1, 2: 1, 3: 2, 4: 2, 5: 2}, {0: 0, 1: 0, 2: 1, 3: 1, 4: 2, 5: 2}, {0: 0, 1: 0, 2: 1, 3: 1, 4: 1, 5: 2}, {0: 0, 1: 1, 2: 1, 3: 2, 4: 2, 5: 2}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "first_block_structure = (\n",
    "    [(6, 0)] * 3 + [(6, 1)] * 3 + [(6, 0)] + [(6, 1)] * 3 + [(6, 0)] * 3 + [(6, 0)]\n",
    ")\n",
    "second_block_structure = (\n",
    "    [(6, 1)] * 3 + [(6, 0)] * 3 + [(6, 0)] + [(6, 0)] * 3 + [(6, 1)] * 3 + [(6, 0)]\n",
    ")\n",
    "for idx, bs in enumerate([first_block_structure, second_block_structure]):\n",
    "    seqmkr = V2RWMSequenceMaker(\n",
    "        exp_type=exp_type,\n",
    "        num_reps=4,\n",
    "        block_structure=bs,\n",
    "        num_conditions=2,\n",
    "        exact_reps=exact_reps,\n",
    ")\n",
    "    seqmkr.make_sequences(start_idx=idx*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V1 sequence creation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Conditions:\n",
    "#     def __init__(self, ns, trial_type):\n",
    "\n",
    "\n",
    "class pseudoRWMSequenceMaker:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        exp_type,\n",
    "        num_reps,\n",
    "        num_conditions=10,\n",
    "        exact_reps=False,\n",
    "        max_consec_goal_reps=24,\n",
    "    ):\n",
    "\n",
    "        # ================ SETTINGS ==========================================================================\n",
    "        assert exp_type in [\n",
    "            \"reverse_points\",\n",
    "        ], f\"{exp_type} is not a valid exp_type\"\n",
    "        self.exp_type = exp_type\n",
    "        self.num_reps = num_reps\n",
    "        self.num_conditions = num_conditions\n",
    "        self.exact_reps = exact_reps\n",
    "        self.to_dir = f\"/Users/ccnlab/Development/sequences/reverse-points/v1/\"\n",
    "        self.num_keys = 3\n",
    "        self.max_stims = 6\n",
    "        # list of (set_size, TRIAL TYPES)\n",
    "        # trial_types: array  where each element represent the sequence\n",
    "        # of trial types (1 = Points/Standard, 0 = Goals/Reverse) a participant will experience\n",
    "        self.block_structure = [\n",
    "            (2, 0),\n",
    "            (2, 1),\n",
    "            (6, 0),\n",
    "            (6, 1),\n",
    "            (2, 0),\n",
    "            (2, 1),\n",
    "            (6, 0),\n",
    "            (6, 1),\n",
    "        ]\n",
    "        self.num_blocks = len(self.block_structure)\n",
    "\n",
    "        self.max_consec_goal_reps = max_consec_goal_reps\n",
    "\n",
    "        # set_size_to_key_list: columns represent keyboard keys\n",
    "        # each column says how many stimuli will be associated with that key\n",
    "        # e.g., 1, 2, 3 means 1 stimulus will be associated with key 0, 2, with key 1, 3 with key 2,\n",
    "        # for a total of 6 items\n",
    "        self.set_size_to_key_list = {\n",
    "            2: np.vstack(\n",
    "                (\n",
    "                    np.array([1, 0, 1]),\n",
    "                    np.array([1, 1, 0]),\n",
    "                    np.array([0, 1, 1]),\n",
    "                    np.array([1, 0, 1]),\n",
    "                )\n",
    "            ),\n",
    "            6: np.vstack(\n",
    "                (\n",
    "                    np.array([1, 2, 3]),\n",
    "                    np.array([1, 3, 2]),\n",
    "                    np.array([2, 2, 2]),\n",
    "                    np.array([3, 2, 1]),\n",
    "                )\n",
    "            ),\n",
    "        }\n",
    "\n",
    "    def make_sequences(self):\n",
    "        from tqdm import trange\n",
    "\n",
    "        for s_i in trange(self.num_conditions):\n",
    "            # blocks: array of length n with each element representing the block's set size and trial type\n",
    "            blocks = self.block_structure.copy()\n",
    "            # Randomize the first half of the blocks\n",
    "            for i in range(0, self.num_blocks // 2, 4):\n",
    "                # has to do a array copy because of the pointer to set object\n",
    "                arr = blocks[i : i + 4]\n",
    "                np.random.shuffle(arr)\n",
    "                blocks[i : i + 4] = arr\n",
    "\n",
    "            # ================ RULES =============================================================================\n",
    "            # block_rules: a list where each element is a dictionary, with keys representing a stimulus image and\n",
    "            # values representing the solution for each stimulus\n",
    "            # here we shuffle within rows (only the first three columns), so that it's not always the same keys\n",
    "            # that have 1, 2, or 3 stimuli associated with them (no difference for rows with 2, 2, 2)\n",
    "            # mix up stim/action within the rule\n",
    "            R_i = {\n",
    "                ns: shuffle_along_axis(keys, axis=1).tolist()\n",
    "                for ns, keys in self.set_size_to_key_list.items()\n",
    "            }\n",
    "            block_rules = []\n",
    "            for block_i, (ns, _) in enumerate(blocks):\n",
    "                key_mapping = R_i[ns].pop()\n",
    "                block_rules.append(\n",
    "                    {\n",
    "                        i: k\n",
    "                        for i, k in enumerate(\n",
    "                            [\n",
    "                                key_i\n",
    "                                for key_i in range(self.num_keys)\n",
    "                                for _ in range(key_mapping[key_i])\n",
    "                            ]\n",
    "                        )\n",
    "                    }\n",
    "                )\n",
    "            print(block_rules)\n",
    "            # ================ STIMULI ===========================================================================\n",
    "            # stim_sets: stimulus sets (folders from where images will be taken for each block)\n",
    "            stim_sets = np.random.permutation(self.num_blocks) + 1\n",
    "\n",
    "            # block_stimuli: will contain dictionaries with an image number for each stimulus\n",
    "            block_stimuli = []\n",
    "            for block_i, (ns, _) in enumerate(blocks):\n",
    "                block_stimuli.append(\n",
    "                    {\n",
    "                        i: s\n",
    "                        for i, s in enumerate(\n",
    "                            (np.random.permutation(self.max_stims) + 1)[0:ns]\n",
    "                        )\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            # block_seqprototypes: will contain dictionaries for each participant, with keys representing a set size and\n",
    "            # values as lists with a sequence of stimuli to be presented\n",
    "            # create a prototype (corresponding to stimuli rather than stimulus images) for each set size\n",
    "            block_seqprototypes = []\n",
    "\n",
    "            # block_sequences: maps block_seqprototypes to corresponding stimulus sequences based on block_stimuli\n",
    "            block_sequences = []\n",
    "            for block_i, (ns, _) in enumerate(blocks):\n",
    "                # worse (but faster) alternative if createstimsequence doesn't work\n",
    "                temp_seqprototype = []\n",
    "                for _ in range(self.num_reps + 1):\n",
    "                    temp_seqprototype = np.hstack(\n",
    "                        (\n",
    "                            temp_seqprototype,\n",
    "                            (shuffled(np.arange(1, ns + 1))),\n",
    "                        )\n",
    "                    )\n",
    "                block_seqprototypes.append(temp_seqprototype)\n",
    "                # turn into stimuli (stimulus image number)\n",
    "                block_sequences.append(\n",
    "                    np.vectorize((block_stimuli[block_i]).get)(\n",
    "                        block_seqprototypes[block_i] - 1\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            # ================ CSV FILE ==========================================================================\n",
    "            # create csv\n",
    "            # rows: stim, correct key, set size, blocks, img_folders, img_nums, trial_type\n",
    "            colnames = [\n",
    "                \"stim\",\n",
    "                \"correct_key\",\n",
    "                \"set_size\",\n",
    "                \"block\",\n",
    "                \"img_folder\",\n",
    "                \"stim_img\",\n",
    "                \"trial_type\",\n",
    "            ]\n",
    "            for block_i, (ns, block_cond) in enumerate(blocks):\n",
    "                block_length = (self.num_reps + 1) * ns  # number of trials in a block\n",
    "\n",
    "                this_block = np.full((len(colnames), block_length), np.nan)\n",
    "\n",
    "                _, unique_idx = np.unique(block_sequences[block_i], return_index=True)\n",
    "                # block_cond = trial_types[block_i]\n",
    "\n",
    "                this_block[0] = block_seqprototypes[block_i]  # stimulus number\n",
    "                this_block[1] = np.vectorize((block_rules[block_i]).get)(\n",
    "                    block_seqprototypes[block_i] - 1\n",
    "                )  # correct key for the stimulus number\n",
    "                this_block[2] = np.repeat(ns, block_length)  # set size\n",
    "                this_block[3] = np.repeat(block_i + 1, block_length)  # block number\n",
    "                this_block[4] = np.repeat(\n",
    "                    stim_sets[block_i], block_length\n",
    "                )  # image folder\n",
    "                this_block[5] = block_sequences[block_i]  # stimulus number\n",
    "                this_block[6] = np.repeat(block_cond, block_length)  # trial type\n",
    "\n",
    "                if block_i == 0:\n",
    "                    train_seq = this_block\n",
    "                    unique_stims = this_block[:, unique_idx]\n",
    "                else:\n",
    "                    train_seq = np.column_stack((train_seq, this_block))\n",
    "                    unique_stims = np.column_stack(\n",
    "                        (unique_stims, this_block[:, unique_idx])\n",
    "                    )\n",
    "\n",
    "            # save output\n",
    "            np.savetxt(\n",
    "                f\"{self.to_dir}seq{s_i+1}_learning.csv\", train_seq, delimiter=\",\"\n",
    "            )\n",
    "\n",
    "        return train_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seqmkr = pseudoRWMSequenceMaker(exp_type=exp_type, num_reps=num_reps, num_conditions=num_conditions, use_matlab=use_matlab, exact_reps=exact_reps)\n",
    "seqmkr = pseudoRWMSequenceMaker(\n",
    "    exp_type=exp_type,\n",
    "    num_reps=num_reps,\n",
    "    num_conditions=10,\n",
    "    exact_reps=exact_reps,\n",
    "    max_consec_goal_reps=16,\n",
    ")\n",
    "# can do max_consec_goal_reps=4 for Reps3 and 16 for Conf3 (a bit slow)\n",
    "seqmkr.make_sequences()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 7 elements, new values have 8 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 15\u001b[0m\n\u001b[1;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../reverse-points/v1/seq\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_practice.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m      4\u001b[0m colnames \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstim\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorrect_key\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_oneshot\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m ]\n\u001b[0;32m---> 15\u001b[0m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m colnames\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_oneshot\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39msize())\n",
      "File \u001b[0;32m~/miniconda3/envs/dl4rl/lib/python3.8/site-packages/pandas/core/generic.py:6002\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   6000\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   6001\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n\u001b[0;32m-> 6002\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__setattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6003\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m   6004\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl4rl/lib/python3.8/site-packages/pandas/_libs/properties.pyx:69\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl4rl/lib/python3.8/site-packages/pandas/core/generic.py:730\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;124;03mThis is called from the cython code when we set the `index` attribute\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;124;03mdirectly, e.g. `series.index = [1, 2, 3]`.\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    729\u001b[0m labels \u001b[38;5;241m=\u001b[39m ensure_index(labels)\n\u001b[0;32m--> 730\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[0;32m~/miniconda3/envs/dl4rl/lib/python3.8/site-packages/pandas/core/internals/managers.py:225\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: AxisInt, new_labels: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;66;03m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[0;32m--> 225\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_set_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis] \u001b[38;5;241m=\u001b[39m new_labels\n",
      "File \u001b[0;32m~/miniconda3/envs/dl4rl/lib/python3.8/site-packages/pandas/core/internals/base.py:70\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m new_len \u001b[38;5;241m!=\u001b[39m old_len:\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength mismatch: Expected axis has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements, new \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 7 elements, new values have 8 elements"
     ]
    }
   ],
   "source": [
    "for i in np.arange(1, 2):\n",
    "    df = pd.read_csv(f\"../reverse-points/seqv2/seq{i}_practice.csv\", header=None).T\n",
    "\n",
    "    colnames = [\n",
    "        \"stim\",\n",
    "        \"correct_key\",\n",
    "        \"set_size\",\n",
    "        \"block\",\n",
    "        \"img_folder\",\n",
    "        \"stim_img\",\n",
    "        \"trial_type\",\n",
    "        \"is_oneshot\",\n",
    "    ]\n",
    "\n",
    "    df.columns = colnames\n",
    "    print(df.groupby([\"block\", \"is_oneshot\"]).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7., 10., 14., 13.,  8.,  1.,  4.,  3.,  5., 12.,  2., 11.,  6.,\n",
       "        9.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.img_folder.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract sequences for self-determined goals task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(1, 11):\n",
    "    df = pd.read_csv(\n",
    "        f\"../reverse-points/v1/seq{i}_learning.csv\",\n",
    "        header=None,\n",
    "    ).T\n",
    "\n",
    "    colnames = [\n",
    "        \"stim\",\n",
    "        \"correct_key\",\n",
    "        \"set_size\",\n",
    "        \"block\",\n",
    "        \"img_folder\",\n",
    "        \"stim_img\",\n",
    "        \"trial_type\",\n",
    "        # \"goal_img\",\n",
    "        # \"nongoal_img\",\n",
    "    ]\n",
    "    df.columns = colnames\n",
    "    df = df[(df.set_size == 2) & (df.trial_type == 0)]\n",
    "    for idx, block_i in enumerate(df.block.unique()):\n",
    "        df.loc[df.block == block_i, \"block\"] = idx + 1\n",
    "        block_df = df[df.block == idx + 1]\n",
    "\n",
    "        stim_img_map = {\n",
    "            old: new for old, new in zip(sorted(block_df.stim_img.unique()), [1, 2])\n",
    "        }\n",
    "        block_df[\"stim_img\"] = block_df[\"stim_img\"].map(stim_img_map)\n",
    "        df.loc[df.block == idx + 1, \"stim_img\"] = block_df[\"stim_img\"]\n",
    "\n",
    "    df.to_csv(f\"../self-determined/seq{i}_learning.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl4rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
